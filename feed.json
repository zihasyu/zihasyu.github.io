{
    "version": "https://jsonfeed.org/version/1",
    "title": "carzo",
    "subtitle": "Zihasyu's Personal Site",
    "icon": "http://example.com/images/favicon.ico",
    "description": "Hope friends and I can get the happiness we deserve",
    "home_page_url": "http://example.com",
    "items": [
        {
            "id": "http://example.com/2024/08/23/Deduplication/",
            "url": "http://example.com/2024/08/23/Deduplication/",
            "title": "24-8-23 Data Compression & Data Deduplication",
            "date_published": "2024-08-23T15:39:40.000Z",
            "content_html": "<h4 id=\"q1-why-is-there-such-a-significant-difference-between-huffman-type-compression-and-post-chunking-compression-are-they-considered-separate-fields-what-are-their-connections-and-differences\"><a class=\"anchor\" href=\"#q1-why-is-there-such-a-significant-difference-between-huffman-type-compression-and-post-chunking-compression-are-they-considered-separate-fields-what-are-their-connections-and-differences\">#</a> Q1: Why is there such a significant difference between Huffman-type compression and post-chunking compression? Are they considered separate fields? What are their connections and differences?</h4>\n<pre><code>我看信息论及其衍生出来的压缩方法都强调distance，例如窗口大小为32K时，他最多用distance为32576的字符串来去重。去重后再进行huffman编码来减少存储开销。  \n而在备份系统中因为chunking的存在，没有distance这个限制，完全可以与几百GiB之前的数据块进行压缩，但相应的chunking后的压缩算法需要recipe来记录源数据（用来解压）。  \n那么请问，为什么huffman编码类压缩和chunking后压缩区别如此大呢，这是否算是两个领域，有什么联系与区别\n</code></pre>\n<h4 id=\"a1\"><a class=\"anchor\" href=\"#a1\">#</a> A1:</h4>\n<pre><code>您提出了一个非常深刻的问题，这涉及到传统压缩算法和现代备份系统中数据去重技术的本质区别。让我们逐步分析这两种方法的特点、区别和联系：\n\n1. 传统压缩算法（如DEFLATE，使用在gzip中）\n\n特点：\n- 使用滑动窗口（通常为32KB）\n- 局部去重（LZ77算法）\n- Huffman编码减少冗余\n\n优势：\n- 单遍处理，内存需求小\n- 压缩和解压速度快\n- 不需要额外的元数据（除了很小的头部信息）\n\n限制：\n- 只能利用局部的重复性（32KB窗口内）\n- 压缩率受限于窗口大小\n\n2. 基于Chunking的备份系统压缩\n\n特点：\n- 全局去重\n- 可以引用任何之前见过的数据块\n- 需要额外的recipe来记录数据引用\n\n优势：\n- 可以利用全局的数据重复性\n- 对于有大量重复数据的场景（如备份），压缩率极高\n- 可以实现增量备份和快速恢复\n\n限制：\n- 需要维护大量元数据（recipe）\n- 通常需要更多的内存和存储空间来管理元数据\n- 压缩和解压可能更慢，尤其是随机访问时\n\n区别和联系：\n\n1. 范围差异：\n   传统压缩关注局部优化，而chunking关注全局优化。\n\n2. 使用场景：\n   传统压缩适用于单个文件或流，chunking更适合大规模存储系统。\n\n3. 元数据开销：\n   传统压缩几乎没有额外元数据，chunking需要大量元数据。\n\n4. 可扩展性：\n   chunking在数据量增加时可以保持高效，而传统压缩效率可能下降。\n\n5. 计算复杂度：\n   传统压缩通常计算复杂度较低，chunking可能需要更复杂的处理。\n\n6. 理论基础：\n   两者都基于信息论，但应用方式不同。传统压缩更直接应用熵编码，chunking更关注冗余消除。\n\n联系：\n\n1. 两种方法都试图利用数据的冗余性。\n2. 在某些系统中，这两种方法可以结合使用：先进行全局去重，然后对unique chunks应用传统压缩。\n3. 都受益于信息论的理论指导，如熵编码和冗余消除。\n\n为什么区别如此大：\n\n1. 设计目标不同：传统压缩针对单个文件优化，chunking针对大规模存储系统优化。\n2. 技术发展：chunking利用了现代系统更大的内存和存储能力。\n3. 应用场景：备份系统面临的数据特性（大量重复）与单个文件压缩不同。\n\n这两种方法确实可以视为压缩领域的两个不同分支，但它们有共同的理论基础，并且在现代系统中常常结合使用。选择哪种方法或如何结合，取决于具体的应用场景、系统资源和性能需求。\n\n如果您想深入了解这两种方法的某个具体方面，或者探讨它们在特定场景下的应用，我可以提供更详细的分析。\n</code></pre>\n<h4 id=\"q2-what-are-the-primary-application-scenarios-for-chunking-methods-and-traditional-compression-methods-respectively\"><a class=\"anchor\" href=\"#q2-what-are-the-primary-application-scenarios-for-chunking-methods-and-traditional-compression-methods-respectively\">#</a> Q2: What are the primary application scenarios for chunking methods and traditional compression methods respectively?</h4>\n<pre><code>所以只有备份系统场景下，才会需要chunking吗，压缩单个文件更倾向于使用LZ77+huffman这种传统方法?\n</code></pre>\n<h4 id=\"a2\"><a class=\"anchor\" href=\"#a2\">#</a> A2</h4>\n<pre><code class=\"language-您的观察非常准确，但实际情况略微复杂一些。让我们深入探讨一下：\">\n1. 备份系统和Chunking\n\n确实，备份系统是Chunking技术最广泛和最有效的应用场景之一。原因包括：\n- 大量重复数据\n- 需要增量备份\n- 快速恢复的需求\n\n2. 单个文件压缩\n\n对于单个文件压缩，传统的LZ77+Huffman（如DEFLATE算法）确实是最常用的方法。原因包括：\n- 速度快\n- 内存需求低\n- 压缩率适中\n- 广泛兼容性\n\n3. Chunking在其他场景的应用\n\n然而，Chunking并不仅限于备份系统。它在其他场景也有应用：\n\na) 大型文件存储系统：\n   - 例如：Dropbox, Google Drive 等云存储服务\n   - 利用跨用户的数据重复性\n\nb) 内容分发网络（CDN）：\n   - 利用Chunking实现高效的内容更新和传输\n\nc) 版本控制系统：\n   - 如Git，使用类似Chunking的方法来高效存储文件的不同版本\n\nd) 大数据处理：\n   - 在某些大数据处理框架中，Chunking用于数据分割和去重\n\ne) 虚拟机镜像管理：\n   - 利用Chunking来高效存储和传输VM镜像\n\n4. 单文件压缩的新发展\n\n即使对于单文件压缩，也有一些新的发展借鉴了Chunking的思想：\n\na) LZMA（用在7z）：\n   - 使用更大的字典大小，接近全局去重的效果\n\nb) Zstandard：\n   - 提供大字典支持，可以利用更广范围的重复性\n\nc) 基于机器学习的压缩：\n   - 如Google的Gipfeli，尝试在单文件中识别和利用更广泛的模式\n\n5. 选择压缩方法的考虑因素\n\n选择使用传统方法还是Chunking（或其变体）取决于多个因素：\n\n- 数据规模\n- 重复模式（局部vs全局）\n- 压缩/解压速度要求\n- 随机访问需求\n- 存储和计算资源限制\n- 兼容性需求\n\n6. 混合方法\n\n在一些高级系统中，会结合使用这两种方法：\n- 首先使用Chunking进行全局去重\n- 然后对unique chunks使用传统压缩方法进一步压缩\n\n结论：\n虽然单文件压缩确实更倾向于使用传统方法，但Chunking的思想已经渗透到了更广泛的应用中。现代压缩技术正在不断融合这两种方法的优点，以适应不同的应用场景和数据特性。\n\n选择合适的方法需要深入理解数据特性和应用需求。在某些情况下，混合使用或选择专门设计的算法可能会带来更好的性能。\n\n如果您对某个特定场景或应用有更具体的问题，我很乐意提供更详细的分析和建议。\n</code></pre>\n<hr />\n<h4 id=\"q3-does-shannons-compression-limit-only-apply-to-traditional-local-compression-and-huffman-coding\"><a class=\"anchor\" href=\"#q3-does-shannons-compression-limit-only-apply-to-traditional-local-compression-and-huffman-coding\">#</a> Q3: Does Shannon's compression limit only apply to traditional local compression and Huffman coding?</h4>\n<pre><code>我可以认为香农压缩极限只作用于传统的localcompression+huffman吗\n</code></pre>\n<h4 id=\"a3\"><a class=\"anchor\" href=\"#a3\">#</a> A3:</h4>\n<pre><code>这个问题触及了信息论的核心概念和其在不同压缩方法中的应用。让我们深入探讨一下：\n\n1. 香农压缩极限的普适性\n\n首先，需要明确的是，香农压缩极限（或香农熵）是一个普适的概念，适用于所有形式的无损数据压缩，不仅限于传统的局部压缩+Huffman编码。香农熵定义了在给定概率分布下，编码信息所需的理论最小平均比特数。\n\n2. 传统局部压缩+Huffman编码\n\n传统方法（如LZ77+Huffman）确实直接使用了香农压缩极限的概念：\n- LZ77利用局部重复性减少冗余\n- Huffman编码试图接近给定概率分布的熵\n\n这些方法在局部范围内（如32KB窗口）尝试接近香农极限。\n\n3. Chunking和全局去重\n\nChunking和全局去重虽然看起来与传统方法很不同，但它们同样受香农压缩极限的约束：\n\n- 理论基础：这些方法本质上是在更大的范围内寻找和消除冗余，这与熵的概念是一致的。\n\n- 全局优化：通过在更大范围内去重，这些方法实际上在尝试接近更大数据集的真实熵。\n\n- Recipe的作用：Recipe（或元数据）本质上是一种编码，其效率同样受熵的限制。\n\n4. 香农极限在不同尺度上的应用\n\n- 局部尺度：传统压缩在小范围内优化\n- 全局尺度：Chunking在更大范围内优化\n- 两者都在各自的尺度上试图接近香农极限\n\n5. 理解的关键点\n\n- 信息源模型：香农极限假设了一个特定的信息源模型。不同的压缩方法可能隐含地假设了不同的模型。\n\n- 计算复杂性：香农极限不考虑计算复杂性，而实际方法必须在效率和压缩率之间权衡。\n\n- 上下文和依赖：更复杂的方法（如Chunking）可能能够捕捉更多的上下文和长程依赖，从而在理论上更接近真实的熵。\n\n6. 结论\n\n因此，我们不能说香农压缩极限只作用于传统的局部压缩+Huffman方法。实际上：\n\n- 香农压缩极限适用于所有无损压缩方法。\n- 不同的方法在不同的尺度和假设下尝试接近这个极限。\n- Chunking和全局去重可以看作是在更大范围内应用熵编码原理的尝试。\n- 所有这些方法都受到信息论原理的指导，只是应用方式和范围不同。\n\n理解这一点很重要，因为它帮助我们认识到，无论是传统方法还是现代的全局去重技术，都是在同一个理论框架下运作的，只是关注点和实现方式不同。这也解释了为什么在某些情况下，全局方法可以实现比局部方法更高的压缩率 —— 它们能够捕捉和利用更大范围内的信息冗余。\n\n如果您想进一步探讨某个具体方法如何与香农极限相关，或者讨论在特定场景下如何最佳地应用这些概念，我很乐意继续深入分析。\n</code></pre>\n<hr />\n<h4 id=\"q4-what-are-the-widely-accepted-definitions-and-relevant-literature-for-traditional-compression-methods-and-chunking-methods\"><a class=\"anchor\" href=\"#q4-what-are-the-widely-accepted-definitions-and-relevant-literature-for-traditional-compression-methods-and-chunking-methods\">#</a> Q4: What are the widely accepted definitions and relevant literature for traditional compression methods and chunking methods?</h4>\n<pre><code>有比较公认的，对传统方法和chunking方法的起名，定义或是相关文献吗\n</code></pre>\n<h4 id=\"a4\"><a class=\"anchor\" href=\"#a4\">#</a> A4:</h4>\n<pre><code>确实有一些比较公认的术语和相关文献来描述这两种方法。让我为您总结一下：\n\n1. 传统方法\n\n通常被称为：\n- 数据压缩 (Data Compression)\n- 通用压缩 (General-purpose Compression)\n- 流压缩 (Stream Compression)\n\n主要算法和技术：\n- LZ77/LZ78 系列\n- Huffman 编码\n- 算术编码\n- 字典编码\n\n重要文献：\n- Ziv, J., &amp; Lempel, A. (1977). A universal algorithm for sequential data compression. IEEE Transactions on Information Theory, 23(3), 337-343.\n- Huffman, D. A. (1952). A Method for the Construction of Minimum-Redundancy Codes. Proceedings of the IRE, 40(9), 1098-1101.\n\n2. Chunking 方法\n\n通常被称为：\n- 数据去重 (Data Deduplication)\n- 内容定义分块 (Content-Defined Chunking)\n- 重复数据删除 (Redundancy Elimination)\n\n主要算法和技术：\n- 固定大小分块 (Fixed-size Chunking)\n- 内容定义分块 (Content-Defined Chunking)\n- 滚动哈希 (Rolling Hash)\n- Rabin fingerprint\n\n重要文献：\n- Muthitacharoen, A., Chen, B., &amp; Mazieres, D. (2001). A low-bandwidth network file system. ACM SIGOPS Operating Systems Review, 35(5), 174-187.\n- Quinlan, S., &amp; Dorward, S. (2002). Venti: A New Approach to Archival Storage. In FAST (Vol. 2, pp. 89-101).\n\n3. 比较和综合\n\n一些文献对这两种方法进行了比较和综合：\n\n- Meister, D., &amp; Brinkmann, A. (2009). Multi-level comparison of data deduplication in a backup scenario. In Proceedings of SYSTOR 2009: The Israeli Experimental Systems Conference (pp. 1-12).\n\n- Paulo, J., &amp; Pereira, J. (2014). A survey and classification of storage deduplication systems. ACM Computing Surveys (CSUR), 47(1), 1-30.\n\n4. 新兴领域\n\n近年来，一些新的研究方向结合了这两种方法的特点：\n\n- 压缩去重 (Compression-aware Deduplication)\n- 学习型压缩 (Learned Compression)\n\n相关文献：\n- Xia, W., Jiang, H., Feng, D., &amp; Hua, Y. (2016). Similarity and locality based indexing for high performance data deduplication. IEEE Transactions on Computers, 65(4), 1162-1176.\n\n- Kraska, T., Beutel, A., Chi, E. H., Dean, J., &amp; Polyzotis, N. (2018). The case for learned index structures. In Proceedings of the 2018 International Conference on Management of Data (pp. 489-504).\n\n这些术语和文献提供了一个良好的起点，可以深入了解这两种方法的理论基础、实际应用和最新发展。传统压缩方法起源较早，有大量经典文献；而chunking和去重技术则相对较新，文献主要集中在过去二十年。\n\n如果您对某个特定领域或技术感兴趣，我可以提供更具体的文献建议。\n</code></pre>\n<hr />\n<h4 id=\"q5-in-specific-dataset-scenarios-does-the-chunking-method-break-shannons-compression-limit\"><a class=\"anchor\" href=\"#q5-in-specific-dataset-scenarios-does-the-chunking-method-break-shannons-compression-limit\">#</a> Q5: In specific dataset scenarios, does the chunking method break Shannon's compression limit?</h4>\n<pre><code>我举个例子，数据集为64TiB，我chunking为每个块8MiB，块内字节非常随机，但块和块之前完全相同。在这种情况下传统无损压缩是遵循香农压缩极限的，但chunking类方法完全可以去重至只剩8MiB+许多recipe。这是否是突破了香农极限呢\n</code></pre>\n<h4 id=\"a5\"><a class=\"anchor\" href=\"#a5\">#</a> A5:</h4>\n<pre><code>您提出了一个非常有趣且富有洞察力的例子。这个例子很好地说明了传统压缩方法和基于chunking的去重方法在特定情况下的巨大差异。让我们深入分析这个情况：\n\n1. 传统无损压缩的表现\n\n在这种情况下，传统的无损压缩（如LZ77+Huffman）确实会受到香农压缩极限的限制：\n\n- 由于每个8MiB块内的字节是非常随机的，传统压缩算法可能无法有效压缩单个块。\n- 传统算法通常使用有限的滑动窗口（如32KB），无法捕捉到不同块之间的相似性。\n\n因此，传统方法可能只能实现很小的压缩率，接近于随机数据的香农熵极限。\n\n2. Chunking方法的表现\n\n使用chunking方法，情况就完全不同了：\n\n- 每个8MiB的块都会被识别为完全相同的。\n- 理论上，可以将64TiB的数据压缩到只有一个8MiB的块加上指向这个块的引用（recipe）。\n\n3. 是否突破了香农极限？\n\n从表面上看，chunking方法似乎&quot;突破&quot;了香农极限。但实际上，这并非突破，而是对信息源的不同理解和建模：\n\na) 信息源的重新定义：\n   - 传统方法将每个字节或小块看作独立的信息单元。\n   - Chunking方法将整个8MiB块视为一个信息单元。\n\nb) 条件熵的应用：\n   - 在chunking的视角下，给定第一个8MiB块，后续所有块的条件熵为零。\n   - 这符合香农的信息论原理，只是应用在了更大的尺度上。\n\nc) 元数据（Recipe）的角色：\n   - Recipe 本身也是数据，需要被计入总的数据量。\n   - Recipe 的大小也受到信息论限制，但相对于原始数据可能很小。\n\n4. 正确理解香农极限\n\n香农极限并没有被突破，而是被在更大的尺度上正确应用了：\n\n- 如果我们将整个64TiB数据视为一个整体，其实际熵非常低（因为只有8MiB的唯一信息）。\n- Chunking方法成功捕捉到了这种大尺度的低熵特性。\n\n5. 关键洞察\n\n这个例子揭示了几个重要观点：\n\na) 尺度的重要性：信息论原理可以在不同尺度上应用，选择合适的尺度至关重要。\n\nb) 模型的适应性：有效的压缩需要选择能够最好地捕捉数据实际特性的模型。\n\nc) 全局vs局部优化：有时全局视角可以发现局部方法无法捕捉的模式。\n\nd) 压缩的本质：真正高效的压缩是找到数据的最简洁表示，而不仅仅是局部的模式匹配。\n\n结论：\nchunking方法在这个例子中的惊人效果并不是突破了香农极限，而是更好地应用了信息论原理。它成功地在更大的尺度上捕捉到了数据的真实熵，这是传统方法因其局限性而无法做到的。\n\n这个例子完美地展示了为什么在某些场景下（如备份系统）chunking和去重技术能够实现如此高的压缩率。它也说明了为什么在设计压缩系统时，理解数据的实际结构和选择合适的压缩策略如此重要。\n</code></pre>\n<hr />\n",
            "tags": [
                "Compression algorithms",
                "chat note",
                "Compression",
                "Storage system"
            ]
        },
        {
            "id": "http://example.com/2024/07/31/Feature-based-Delta-Summary/",
            "url": "http://example.com/2024/07/31/Feature-based-Delta-Summary/",
            "title": "Feature-based Delta Summary",
            "date_published": "2024-07-30T16:50:44.000Z",
            "content_html": "<h2 id=\"fearture-based-delta共性\"><a class=\"anchor\" href=\"#fearture-based-delta共性\">#</a> Fearture-based  Delta 共性</h2>\n<h3 id=\"delta-compression-系统流程图\"><a class=\"anchor\" href=\"#delta-compression-系统流程图\">#</a> Delta Compression 系统流程图</h3>\n<p><img data-src=\"https://notepic-1327795028.cos.ap-chengdu.myqcloud.com/pic/202407291513831.png\" alt=\"image.png\" /><br />\nDeduplication 能过滤掉重复块，即 savesize 为 0，只留下一个 recipe 大小的存储开销用于日后恢复。所以需要计算 SF 并去查 SFindex 表的块都是已经用 FP 去重过滤后得到的 unique chunk。后续会详细介绍独属于对 unique chunk 的处理，这部分是 delta compression system 比只去重系统要增加的部分。</p>\n<h3 id=\"fearture-based-通用的流程图\"><a class=\"anchor\" href=\"#fearture-based-通用的流程图\">#</a> Fearture-based 通用的流程图</h3>\n<p><img data-src=\"https://notepic-1327795028.cos.ap-chengdu.myqcloud.com/pic/202407291506456.png\" alt=\"image.png\" /><br />\n 每个独特快都要计算 SF (若干个 ori feature 经过线性变换后得到的 1 个新的 feature 叫做 super feature)，先拿去查表，有相似块的话做 delta compression，没有的话把算好的 SF 插入 SFindex 中即可，那之后对当前块做 local compression 后持久化。</p>\n<h3 id=\"sf-index相关-的通用流程图\"><a class=\"anchor\" href=\"#sf-index相关-的通用流程图\">#</a> SF-index 相关 的通用流程图</h3>\n<p><img data-src=\"https://notepic-1327795028.cos.ap-chengdu.myqcloud.com/pic/202407291526625.png\" alt=\"image.png\" /><br />\n 再将需要实现的部分总结并抽象出来，发现实际上不同 feature-based 方法的核心与差异在于 SF 的计算（Rolling hash，Linear transform）这个方法，此外还要根据 SFindex 的结构再去实现 SF_Find, SF_insert 这两个方法。故在实现不同的 feature-based 方法时重点实现这三个函数，其余很多部分可以复用。</p>\n<h2 id=\"sf-methods\"><a class=\"anchor\" href=\"#sf-methods\">#</a> SF Methods</h2>\n<h3 id=\"n-transform-sf\"><a class=\"anchor\" href=\"#n-transform-sf\">#</a> N-transform-SF</h3>\n<p>开山之作，作者写的很随意，拿和同事的对话当引言，真正意义上的 master piece，去看原文吧。<br />\n实现要点：</p>\n<ul>\n<li>Rolling hash: <strong>Rabin 指纹</strong>去算滚动哈希，对同一个块用 12 套参数 (a,b) 求得 12 个不同的原始特征 ori feature</li>\n<li>Linear transform: 将 12 个 ori feature 分 3 组，线性变换为 3 个 SF，存储在三个哈希表中。</li>\n<li>压缩效果较好，时间开销极大<br />\n<img data-src=\"https://notepic-1327795028.cos.ap-chengdu.myqcloud.com/pic/202407291744198.png\" alt=\"image.png\" /></li>\n</ul>\n<h3 id=\"finesse\"><a class=\"anchor\" href=\"#finesse\">#</a> Finesse</h3>\n<p>经常被拿来对比的经典作。<br />\n实现要点：</p>\n<ul>\n<li>Rolling hash: <strong>Rabin 指纹</strong>去算滚动哈希，将一个 chunk 分为 12 个 subchunk，那之后用同 1 套参数对每个 subchunk 求 1 个 ori feature，这样合计 12 个 ori feature。// 只有 Finesse 做了分子块这个操作，有个隐形的限制是原始块不能小于一定值，这个值是其他方法的 12 倍大小，对 chunking 方式有一定限制。</li>\n<li>Linear transform: 将 12 个 ori feature 先组内排序，再分 3 组，线性变换为 3 个 SF，存储在三个哈希表中。</li>\n<li>压缩效果较差，时间开销减少一些<br />\n<img data-src=\"https://notepic-1327795028.cos.ap-chengdu.myqcloud.com/pic/202407291744886.png\" alt=\"image.png\" /></li>\n</ul>\n<h3 id=\"odess\"><a class=\"anchor\" href=\"#odess\">#</a> Odess</h3>\n<p>在压缩效果和计算开销上都非常务实的作品，但可惜行文中自己的工作量不太够，没能中更好的期刊。<br />\n实现要点：</p>\n<ul>\n<li>Rolling hash: <strong>Gear 滚动哈希 + CDS 抽样</strong>去算滚动哈希，利用 CDS 使得只用对 1/128 个基于内容而定的窗口计算哈希值，虽然对同一个块用 12 套参数 (a,b) 求得 12 个不同的原始特征 ori feature，但因为是抽样计算，所以耗时比 finesse 还要短。</li>\n<li>Linear transform: 将 12 个 ori feature 分 3 组，线性变换为 3 个 SF，存储在三个哈希表中。</li>\n<li>压缩效果较好，时间开销减少更多<br />\n<img data-src=\"https://notepic-1327795028.cos.ap-chengdu.myqcloud.com/pic/202407291747134.png\" alt=\"image.png\" /></li>\n</ul>\n<h3 id=\"palantir\"><a class=\"anchor\" href=\"#palantir\">#</a> Palantir</h3>\n<p>提出了一些观点值得思考，但工程角度的总体评价远不如 Odess<br />\n 实现要点：</p>\n<ul>\n<li>Rolling hash: <strong>Gear 滚动哈希 + CDS 抽样</strong>去算滚动哈希，利用 CDS 使得只用对 1/128 个基于内容而定的窗口计算哈希值，虽然对同一个块用 12 套参数 (a,b) 求得 12 个不同的原始特征 ori feature，但因为是抽样计算，所以耗时比 finesse 还要短。</li>\n<li>Linear transform: 将 12 个 ori feature 分 3 组，线性变换为 3 个 SF，存储在 3 个哈希表中。第二层：将 12 个 ori feature 分 4 组，线性变换为 4 个 SF，存储在 4 个哈希表中。第三层：将 12 个 ori feature 分 4 组，线性变换为 6 个 SF，存储在 6 个哈希表中。合计 13 个 index。// 更多的空间开销和计算开销</li>\n<li>为减少每个 unique chunk 有 13 个 SFindex 的开销，推出了生命周期机制，第二层的 index 在插入 5 个版本后清除，第三层的 index 在插入 2 个版本后清除。// 更多的计算开销。</li>\n<li>因清除的存在，palantir 提出该设计下需要给重复块也计算 SF，来查询是否需要补充第 2、3 层的 SFindex。// 更多的计算开销</li>\n<li>压缩效果短期非常好，长期效果非常差，时间开销极其多。</li>\n</ul>\n<h2 id=\"conclusion\"><a class=\"anchor\" href=\"#conclusion\">#</a> Conclusion</h2>\n<p>大部分改进 delta compression 的论文都是从改进本章节 SF 的计算与选择出发的，改进的指标会是吞吐量或者 overall compression ratio。<br />\n不同的 SF 组装方法，本质是设计了一个不同相似度阈值，较过低或过高都会有损压缩率。每个块及以其作 base 的 delta chunk 的最优阈值是不同的，每个数据集更是不同。当然在小数据集上降低阈值寻找更多的相似块是有利于 overall ratio 的。<br />\n而 palantir 看似设计了多个阈值，但长远来看还是降低了阈值，在追求 optimal overall ratio 的道路上这是有害的。</p>\n",
            "tags": [
                "Compression algorithms",
                "Compression",
                "Storage system",
                "Operating system",
                "Computer science",
                "Feature-based"
            ]
        },
        {
            "id": "http://example.com/2024/07/22/hello-world/",
            "url": "http://example.com/2024/07/22/hello-world/",
            "title": "Hello World",
            "date_published": "2024-07-22T13:54:25.496Z",
            "content_html": "<p>Welcome to <span class=\"exturl\" data-url=\"aHR0cHM6Ly9oZXhvLmlvLw==\">Hexo</span>! This is your very first post. Check <span class=\"exturl\" data-url=\"aHR0cHM6Ly9oZXhvLmlvL2RvY3Mv\">documentation</span> for more info. If you get any problems when using Hexo, you can find the answer in <span class=\"exturl\" data-url=\"aHR0cHM6Ly9oZXhvLmlvL2RvY3MvdHJvdWJsZXNob290aW5nLmh0bWw=\">troubleshooting</span> or you can ask me on <span class=\"exturl\" data-url=\"aHR0cHM6Ly9naXRodWIuY29tL2hleG9qcy9oZXhvL2lzc3Vlcw==\">GitHub</span>.</p>\n<h2 id=\"quick-start\"><a class=\"anchor\" href=\"#quick-start\">#</a> Quick Start</h2>\n<h3 id=\"create-a-new-post\"><a class=\"anchor\" href=\"#create-a-new-post\">#</a> Create a new post</h3>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"><span>h</span></figcaption><table><tr><td data-num=\"1\"></td><td><pre>$ hexo new <span class=\"token string\">\"My New Post\"</span></pre></td></tr></table></figure><p>More info: <span class=\"exturl\" data-url=\"aHR0cHM6Ly9oZXhvLmlvL2RvY3Mvd3JpdGluZy5odG1s\">Writing</span></p>\n<h3 id=\"run-server\"><a class=\"anchor\" href=\"#run-server\">#</a> Run server</h3>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"><span>h</span></figcaption><table><tr><td data-num=\"1\"></td><td><pre>$ hexo server</pre></td></tr></table></figure><p>More info: <span class=\"exturl\" data-url=\"aHR0cHM6Ly9oZXhvLmlvL2RvY3Mvc2VydmVyLmh0bWw=\">Server</span></p>\n<h3 id=\"generate-static-files\"><a class=\"anchor\" href=\"#generate-static-files\">#</a> Generate static files</h3>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"><span>h</span></figcaption><table><tr><td data-num=\"1\"></td><td><pre>$ hexo generate</pre></td></tr></table></figure><p>More info: <span class=\"exturl\" data-url=\"aHR0cHM6Ly9oZXhvLmlvL2RvY3MvZ2VuZXJhdGluZy5odG1s\">Generating</span></p>\n<h3 id=\"deploy-to-remote-sites\"><a class=\"anchor\" href=\"#deploy-to-remote-sites\">#</a> Deploy to remote sites</h3>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"><span>h</span></figcaption><table><tr><td data-num=\"1\"></td><td><pre>$ hexo deploy</pre></td></tr></table></figure><p>More info: <span class=\"exturl\" data-url=\"aHR0cHM6Ly9oZXhvLmlvL2RvY3Mvb25lLWNvbW1hbmQtZGVwbG95bWVudC5odG1s\">Deployment</span></p>\n",
            "tags": []
        },
        {
            "id": "http://example.com/2024/07/04/Summary%20of%20Chunking/",
            "url": "http://example.com/2024/07/04/Summary%20of%20Chunking/",
            "title": "Chunking summary",
            "date_published": "2024-07-04T11:48:04.000Z",
            "content_html": "<h2 id=\"chunking-flow\"><a class=\"anchor\" href=\"#chunking-flow\">#</a> Chunking flow</h2>\n<h3 id=\"flow-chart\"><a class=\"anchor\" href=\"#flow-chart\">#</a> Flow chart</h3>\n<p><img data-src=\"https://notepic-1327795028.cos.ap-chengdu.myqcloud.com/pic/202407251358457.png\" alt=\"image.png\" /></p>\n<h3 id=\"why-only-read-part\"><a class=\"anchor\" href=\"#why-only-read-part\">#</a> Why only Read part\\</h3>\n<p>we unuslly read 128MiB a time from the Tar to Chunking. this will prevent too much memory from being consumed.<br />\nwhen the ReadFileBuffer is about to reach the end, we need to seekg the next beginning of the buffer.</p>\n<h3 id=\"code-sample\"><a class=\"anchor\" href=\"#code-sample\">#</a> Code sample</h3>\n<figure class=\"highlight cpp\"><figcaption data-lang=\"C++\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">void</span> <span class=\"token class-name\">Chunker</span><span class=\"token double-colon punctuation\">::</span><span class=\"token function\">Chunking</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    <span class=\"token keyword\">bool</span> end <span class=\"token operator\">=</span> <span class=\"token boolean\">false</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    <span class=\"token keyword\">uint32_t</span> totalOffset <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    <span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token operator\">!</span>end<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>        <span class=\"token function\">memset</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">char</span> <span class=\"token operator\">*</span><span class=\"token punctuation\">)</span>readFileBuffer<span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token keyword\">sizeof</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">uint8_t</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> READ_FILE_SIZE<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>        inputFile<span class=\"token punctuation\">.</span><span class=\"token function\">read</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">char</span> <span class=\"token operator\">*</span><span class=\"token punctuation\">)</span>readFileBuffer<span class=\"token punctuation\">,</span> <span class=\"token keyword\">sizeof</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">uint8_t</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> READ_FILE_SIZE<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>        end <span class=\"token operator\">=</span> inputFile<span class=\"token punctuation\">.</span><span class=\"token function\">eof</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>        size_t len <span class=\"token operator\">=</span> inputFile<span class=\"token punctuation\">.</span><span class=\"token function\">gcount</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>        <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>len <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>        <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>            <span class=\"token keyword\">break</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>        <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>        localOffset <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre>        <span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>len <span class=\"token operator\">-</span> localOffset<span class=\"token punctuation\">)</span> <span class=\"token operator\">>=</span> MAXCHUNKSIZE<span class=\"token punctuation\">)</span> <span class=\"token operator\">||</span> <span class=\"token punctuation\">(</span>end <span class=\"token operator\">&amp;&amp;</span> <span class=\"token punctuation\">(</span>localOffset <span class=\"token operator\">&lt;</span> len<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre>        <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>            Chunk_t chunk<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre>            <span class=\"token keyword\">uint32_t</span> cp <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre>            cp <span class=\"token operator\">=</span> <span class=\"token function\">CutPoint</span><span class=\"token punctuation\">(</span>readFileBuffer <span class=\"token operator\">+</span> localOffset<span class=\"token punctuation\">,</span> len <span class=\"token operator\">-</span> localOffset<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>            chunk<span class=\"token punctuation\">.</span>chunkPtr <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">uint8_t</span> <span class=\"token operator\">*</span><span class=\"token punctuation\">)</span><span class=\"token function\">malloc</span><span class=\"token punctuation\">(</span>cp<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre>            <span class=\"token function\">memcpy</span><span class=\"token punctuation\">(</span>chunk<span class=\"token punctuation\">.</span>chunkPtr<span class=\"token punctuation\">,</span> readFileBuffer <span class=\"token operator\">+</span> localOffset<span class=\"token punctuation\">,</span> cp<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"23\"></td><td><pre>            chunk<span class=\"token punctuation\">.</span>chunkSize <span class=\"token operator\">=</span> cp<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre>            localOffset <span class=\"token operator\">+=</span> cp<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"25\"></td><td><pre>        <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"26\"></td><td><pre>        totalOffset <span class=\"token operator\">+=</span> localOffset<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"27\"></td><td><pre>        inputFile<span class=\"token punctuation\">.</span><span class=\"token function\">seekg</span><span class=\"token punctuation\">(</span>totalOffset<span class=\"token punctuation\">,</span> ios_base<span class=\"token double-colon punctuation\">::</span>beg<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"28\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"29\"></td><td><pre>    <span class=\"token keyword\">return</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"30\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><h2 id=\"chunking-methods\"><a class=\"anchor\" href=\"#chunking-methods\">#</a> Chunking methods</h2>\n<p>the different  chunking methods are reflected in the way cp is obtained.</p>\n<figure class=\"highlight cpp\"><figcaption data-lang=\"C++\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">uint32_t</span> cp <span class=\"token operator\">=</span> <span class=\"token function\">Chunking</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><h3 id=\"fixed-size\"><a class=\"anchor\" href=\"#fixed-size\">#</a> Fixed-size</h3>\n<p>As a tradeoff between Deduplication and throughput, chunking methods typically use 8KiB as the desired average size.</p>\n<figure class=\"highlight cpp\"><figcaption data-lang=\"C++\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">uint32_t</span> <span class=\"token class-name\">Chunker</span><span class=\"token double-colon punctuation\">::</span><span class=\"token function\">FixedSize</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>\t\t<span class=\"token keyword\">return</span> FixedChunkSize<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><p>But the fixed-size chunking will encounter a very serious boundary migration problem, which will allow the reactivity to drop.</p>\n<h3 id=\"cdc\"><a class=\"anchor\" href=\"#cdc\">#</a> CDC</h3>\n<p>When the sliding hash in the window is equal to 0 with the mask that operation set in advance, it is used as a breakpoint.This is called content-defined chunking.</p>\n<figure class=\"highlight cpp\"><figcaption data-lang=\"C++\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">uint32_t</span> <span class=\"token class-name\">Chunker</span><span class=\"token double-colon punctuation\">::</span><span class=\"token function\">CutPointCDC</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">const</span> <span class=\"token keyword\">uint8_t</span> <span class=\"token operator\">*</span>src<span class=\"token punctuation\">,</span> <span class=\"token keyword\">const</span> <span class=\"token keyword\">uint32_t</span> len<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    <span class=\"token keyword\">uint32_t</span> fp <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    <span class=\"token keyword\">uint32_t</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> len<span class=\"token punctuation\">;</span> i<span class=\"token operator\">++</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>        fp <span class=\"token operator\">=</span> fp <span class=\"token operator\">-</span> Rabin<span class=\"token punctuation\">[</span>src<span class=\"token punctuation\">[</span>i<span class=\"token operator\">-</span>windowSize<span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> Rabin<span class=\"token punctuation\">[</span>src<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>        <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token operator\">!</span><span class=\"token punctuation\">(</span>fp <span class=\"token operator\">&amp;</span> MASK_GEAR<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>        <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>            <span class=\"token keyword\">return</span> <span class=\"token punctuation\">(</span>i <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>        <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>    <span class=\"token keyword\">return</span> i<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>The expected block size is related to the significant bit 1 of the mask. For example, if I want the block size to be 8KiB on average, then I need 13 1's in the mask.</p>\n<h3 id=\"gear\"><a class=\"anchor\" href=\"#gear\">#</a> Gear</h3>\n<p>Gear Hash reduces the computational overhead of the rolling hash by fixing the significant bit 1 of the mask to be the least significant bit, so that gear can obtain the rolling hash value by bit operation.</p>\n<figure class=\"highlight cpp\"><figcaption data-lang=\"C++\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">uint32_t</span> <span class=\"token class-name\">Chunker</span><span class=\"token double-colon punctuation\">::</span><span class=\"token function\">CutPointGear</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">const</span> <span class=\"token keyword\">uint8_t</span> <span class=\"token operator\">*</span>src<span class=\"token punctuation\">,</span> <span class=\"token keyword\">const</span> <span class=\"token keyword\">uint32_t</span> len<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    <span class=\"token keyword\">uint32_t</span> fp <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    <span class=\"token keyword\">uint32_t</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> len<span class=\"token punctuation\">;</span> i<span class=\"token operator\">++</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>        fp <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>fp <span class=\"token operator\">>></span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> GEAR<span class=\"token punctuation\">[</span>src<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>        <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token operator\">!</span><span class=\"token punctuation\">(</span>fp <span class=\"token operator\">&amp;</span> MASK_GEAR<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>        <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>            <span class=\"token keyword\">return</span> <span class=\"token punctuation\">(</span>i <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>        <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>    <span class=\"token keyword\">return</span> i<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><h3 id=\"fastcdc\"><a class=\"anchor\" href=\"#fastcdc\">#</a> FastCDC</h3>\n<p>FastCDC solves two problems, one is to further improve throughput, and the other is to standardize block sizes in the 4KiB-16KiB range. It skips the first 4KiB without having to compute the hash, and its mask is also standardized to be bitwise, so that when it reaches 16KiB, it immediately gets the breakpoint, whether it meets the breakpoint condition or not. In addition, to achieve an average size of 8KiB, he uses different masks to generate breakpoints in 4K-8K and 8K-16K.</p>\n<figure class=\"highlight cpp\"><figcaption data-lang=\"C++\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">uint32_t</span> <span class=\"token class-name\">Chunker</span><span class=\"token double-colon punctuation\">::</span><span class=\"token function\">CutPointFastCDC</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">const</span> <span class=\"token keyword\">uint8_t</span> <span class=\"token operator\">*</span>src<span class=\"token punctuation\">,</span> <span class=\"token keyword\">const</span> <span class=\"token keyword\">uint32_t</span> len<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    <span class=\"token keyword\">uint32_t</span> n<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    <span class=\"token keyword\">uint32_t</span> fp <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    <span class=\"token keyword\">uint32_t</span> i<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    i <span class=\"token operator\">=</span> <span class=\"token function\">min</span><span class=\"token punctuation\">(</span>len<span class=\"token punctuation\">,</span> <span class=\"token generic-function\"><span class=\"token function\">static_cast</span><span class=\"token generic class-name\"><span class=\"token operator\">&lt;</span><span class=\"token keyword\">uint32_t</span><span class=\"token operator\">></span></span></span><span class=\"token punctuation\">(</span>minChunkSize<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>    n <span class=\"token operator\">=</span> <span class=\"token function\">min</span><span class=\"token punctuation\">(</span>normalSize<span class=\"token punctuation\">,</span> len<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>    <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> n<span class=\"token punctuation\">;</span> i<span class=\"token operator\">++</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>    <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>        fp <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>fp <span class=\"token operator\">>></span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> GEAR<span class=\"token punctuation\">[</span>src<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>        <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token operator\">!</span><span class=\"token punctuation\">(</span>fp <span class=\"token operator\">&amp;</span> maskS<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>        <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>            <span class=\"token keyword\">return</span> <span class=\"token punctuation\">(</span>i <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>        <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre></pre></td></tr><tr><td data-num=\"17\"></td><td><pre>    n <span class=\"token operator\">=</span> <span class=\"token function\">min</span><span class=\"token punctuation\">(</span><span class=\"token generic-function\"><span class=\"token function\">static_cast</span><span class=\"token generic class-name\"><span class=\"token operator\">&lt;</span><span class=\"token keyword\">uint32_t</span><span class=\"token operator\">></span></span></span><span class=\"token punctuation\">(</span>maxChunkSize<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> len<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>    <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> n<span class=\"token punctuation\">;</span> i<span class=\"token operator\">++</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre>    <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre>        fp <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>fp <span class=\"token operator\">>></span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> GEAR<span class=\"token punctuation\">[</span>src<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>        <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token operator\">!</span><span class=\"token punctuation\">(</span>fp <span class=\"token operator\">&amp;</span> maskL<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre>        <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"23\"></td><td><pre>            <span class=\"token keyword\">return</span> <span class=\"token punctuation\">(</span>i <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre>        <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"25\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"26\"></td><td><pre>    <span class=\"token keyword\">return</span> i<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"27\"></td><td><pre><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><h3 id=\"mtar\"><a class=\"anchor\" href=\"#mtar\">#</a> mTar</h3>\n<p>mTar argues that the metadata head of the periodic appearance of tar reduces the Deduplication rate</p>\n<figure class=\"highlight cpp\"><figcaption data-lang=\"C++\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">void</span> <span class=\"token function\">MTar</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>\ttranslate the Tar files to mTar files<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre></pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token function\">FastCDC</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><h2 id=\"conclusion\"><a class=\"anchor\" href=\"#conclusion\">#</a> Conclusion</h2>\n<p>The chunking method is a part of the compression system that determines the theoretical upper bound. If the obtained chunk contains extremely high boundary offset, then the best feature value selection method cannot obtain excellent results.</p>\n",
            "tags": [
                "Compression algorithms",
                "Chunking",
                "Compression",
                "Storage system",
                "Operating system",
                "Computer science"
            ]
        }
    ]
}